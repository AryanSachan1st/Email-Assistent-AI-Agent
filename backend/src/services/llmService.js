import axios from 'axios';
import 'dotenv/config'; // To ensure environment variables are loaded

/**
 * Calls the external LLM API (OpenAI) with the constructed prompt.
 * @param {string} fullPrompt - The combined prompt string (Email + Stored Prompt + User Query).
 * @returns {Promise<string>} - The text response generated by the LLM.
 */
export async function callLLMApi(fullPrompt) {
  // --- Configuration ---
  const API_KEY = process.env.OPENAI_API_KEY; 
  
  if (!API_KEY || API_KEY.length < 30) {
    console.error("Critical Error: OPENAI_API_KEY is missing or too short. Please check your backend/.env file.");
    throw new Error("OPENAI_API_KEY is not configured correctly.");
  }
  
  // NOTE: Logging first few chars of API key for verification.
  console.log(`LLM Service: Using OpenAI API Key starting with: ${API_KEY.substring(0, 8)}...`); 

  // Using the OpenAI Chat Completions endpoint
  const API_ENDPOINT = `https://api.openai.com/v1/chat/completions`;
  const MODEL_NAME = 'gpt-3.5-turbo'; // A fast and reliable model for these tasks
  
  // --- Request Body Structure (OpenAI Format) ---
  const requestBody = {
    model: MODEL_NAME,
    messages: [
        { role: "user", content: fullPrompt },
    ],
    temperature: 0.1, 
    max_tokens: 2048,
  };

  try {
    // Implementing basic exponential backoff for robustness
    const maxRetries = 3;
    let delay = 1000;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
            const response = await axios.post(API_ENDPOINT, requestBody, {
              headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${API_KEY}`
              },
              timeout: 30000 // 30 second timeout
            });

            // --- Extract and Return the Generated Text (OpenAI Format) ---
            const generatedText = response.data.choices?.[0]?.message?.content;
            
            if (generatedText) {
              return generatedText;
            } else {
              console.error(`LLM returned no text on attempt ${attempt}. Response Data:`, response.data);
              throw new Error("LLM failed to generate a valid text response.");
            }
        } catch (error) {
            // Error handling tailored for common OpenAI API status codes
            const status = error.response?.status;
            const errorCode = error.response?.data?.error?.code; // Get specific OpenAI error code

            if (errorCode === 'insufficient_quota') {
                // --- SIMULATION FALLBACK FOR QUOTA ERROR ---
                console.warn("Quota Exceeded. Returning Simulated LLM Response.");
                return `
                ***[SIMULATED LLM RESPONSE]***
                Your OpenAI quota is currently exceeded (Error 429).
                
                The agent received the following instruction:
                ${fullPrompt.substring(0, 200)}... (truncated)

                Based on the instruction, the agent would normally provide:
                - A Summary (if asked to summarize)
                - A JSON Array (if asked to extract tasks)
                - A Draft Reply (if asked to draft).
                
                Please update your OpenAI billing details to receive a live response.
                `;
            }

            if (attempt === maxRetries || (status !== 429 && status !== 500)) { 
                // Re-throw if it's the last attempt or not a standard retryable error (429 or 500)
                throw error;
            }
            console.log(`API issue detected (Status ${status}, Attempt ${attempt}). Retrying in ${delay}ms...`);
            await new Promise(resolve => setTimeout(resolve, delay));
            delay *= 2; // Exponential backoff
        }
    }
    
  } catch (error) {
    if (axios.isAxiosError(error)) {
      // Log the specific API response error
      const status = error.response?.status;
      const data = error.response?.data;
      
      console.error(`Axios Error - Status ${status}:`, data);
      
      if (status === 401) {
        throw new Error(`LLM API request failed: Unauthorized (Invalid OpenAI API Key).`);
      }
      if (status === 400) {
        throw new Error(`LLM API request failed: Bad Request (Check your Prompt structure).`);
      }
      
      throw new Error(`LLM API request failed: Request failed with status code ${status}`);
    }
    throw error;
  }
}